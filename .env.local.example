# ============================================
# 快速配置示例 - 选择一种方式
# ============================================

# --------------------------------------------
# 方式 1: 使用 Ollama (默认，推荐用于开发)
# --------------------------------------------
# 无需配置，确保 Ollama 服务运行即可
# 运行: ollama serve

VITE_AI_PROVIDER=ollama
VITE_OLLAMA_BASE_URL=http://localhost:11434
VITE_OLLAMA_MODEL=qwen2.5-coder:1.5b


# --------------------------------------------
# 方式 2: 使用 OpenAI API
# --------------------------------------------
# 取消下面的注释并填入你的 API Key

# VITE_AI_PROVIDER=openai
# VITE_OPENAI_BASE_URL=https://api.openai.com/v1
# VITE_OPENAI_API_KEY=sk-your-api-key-here
# VITE_OPENAI_MODEL=gpt-3.5-turbo


# --------------------------------------------
# 方式 3: 使用 Azure OpenAI
# --------------------------------------------
# 取消下面的注释并填入你的配置

# VITE_AI_PROVIDER=openai
# VITE_OPENAI_BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
# VITE_OPENAI_API_KEY=your-azure-api-key
# VITE_OPENAI_MODEL=gpt-35-turbo


# --------------------------------------------
# 方式 4: 使用本地部署的兼容 OpenAI API 的服务
# --------------------------------------------
# 例如: vLLM, LocalAI, Text Generation WebUI 等

# VITE_AI_PROVIDER=openai
# VITE_OPENAI_BASE_URL=http://localhost:8000/v1
# VITE_OPENAI_API_KEY=dummy-key
# VITE_OPENAI_MODEL=your-model-name


# ============================================
# 使用说明
# ============================================
# 1. 复制此文件为 .env.local
# 2. 取消注释你想使用的配置方式
# 3. 填入实际的配置值
# 4. 保存文件并重启开发服务器: npm run dev
# 5. .env.local 不会被提交到 Git（已在 .gitignore 中）
